{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behandling av værdata\n",
    "<style>\n",
    "p {\n",
    "    line-height: 1.5; \n",
    "}\n",
    "</style>\n",
    "Her skal vi behandle og manipulere dataen vi har hentet, slik at den blir lettere å lese. Deretter skal vi senere visualisere dette. Vi gjør ulike operasjoner med dataen for å forbedre den for videre analyse, samt forsøker å oppfylle vurderingskriteriene. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametere: {'sources': 'SN68230,SN18700,SN50540', 'elements': 'mean(air_temperature P1D),sum(precipitation_amount P1D),mean(wind_speed P1D)', 'referencetime': '2022-01-01/2023-01-01', 'timeoffsets': 'default', 'timeresolutions': 'P1D', 'levels': 'default'}\n",
      "Data lagret i ../data/BehandletVaerData.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Henter API-key/Client-id fra .env filen\n",
    "client_id = os.getenv(\"client_id\")\n",
    "\n",
    "with open('../data/Byer.json', 'r') as f:\n",
    "    byer = json.load(f)\n",
    "\n",
    "byerAsString = ','.join(byer.values())\n",
    "\n",
    "element_id = \"mean(air_temperature P1D),sum(precipitation_amount P1D),mean(wind_speed P1D)\"  # Temperatur, nedbør og vindhastighet\n",
    "start_dato = \"2022-01-01\"  # Startdato\n",
    "slutt_dato = \"2023-01-01\"  # Sluttdato\n",
    "\n",
    "# Define endpoint and parameters\n",
    "endpoint = 'https://frost.met.no/observations/v0.jsonld'\n",
    "parameters = {\n",
    "    \"sources\": byerAsString,\n",
    "    \"elements\": element_id,\n",
    "    \"referencetime\": f\"{start_dato}/{slutt_dato}\",\n",
    "    \"timeoffsets\": \"default\",\n",
    "    \"timeresolutions\": \"P1D\",\n",
    "    \"levels\": \"default\"\n",
    "}\n",
    "print(f\"Parametere: {parameters}\")\n",
    "\n",
    "# Sender forespørsel til Frost API\n",
    "response = requests.get(endpoint, params=parameters, auth=(client_id, ''))\n",
    "\n",
    "# Sjekker om forespørselen var vellykket\n",
    "if response.status_code != 200:\n",
    "    print(f\"Error! Status code: {response.status_code}\")\n",
    "    print(f\"Message: {response.json().get('error', {}).get('message', 'Ingen melding gitt')}\")\n",
    "    print(f\"Reason: {response.json().get('error', {}).get('reason', 'Ingen årsak gitt')}\")\n",
    "    exit()\n",
    "\n",
    "# Henter JSON-data\n",
    "json_data = response.json()\n",
    "if 'data' not in json_data:\n",
    "    print(\"Ingen data funnet i forespørselen.\")\n",
    "    print(json_data)\n",
    "    exit()\n",
    "\n",
    "# Prosesserer data til en DataFrame\n",
    "data = json_data['data']\n",
    "rows = []  # Liste for å samle alle rader\n",
    "for item in data:\n",
    "    for observation in item['observations']:\n",
    "        row = {\n",
    "            'sourceId': item['sourceId'].split(':')[0],  # Fjern ':0' fra sourceId\n",
    "            'referenceTime': item['referenceTime'],\n",
    "            'elementId': observation['elementId'],\n",
    "            'value': observation['value'],\n",
    "            'unit': observation['unit'],\n",
    "            'codequality': observation.get('qualityCode', '')  # Henter kvalitetskoden\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "\n",
    "# Gjør om litt på dataer slik at de blir lettere å jobbe med og penere å se på i CSV-filen.\n",
    "df['referenceTime'] = pd.to_datetime(df['referenceTime']).dt.date # Fjerner tid og beholder bare dato\n",
    "df[['statistikk', 'variable']] = df['elementId'].str.extract(r'(\\w+)\\(([^)]+)') # Splitter elementId i to kolonner, en for verdi og en for enhet. \n",
    "df['by'] = df['sourceId'].map({v: k for k, v in byer.items()})  # Legger til en ny kolonne for bynavn basert på sourceId\n",
    "df = df[['by', 'sourceId', 'referenceTime', 'statistikk', 'variable', 'value', 'unit', 'codequality']] #Endrer på oppsettet på kolonnene i dataen vi henter ut.\n",
    "\n",
    "# Gjør \"codequality\"-verdiene mer forståelige. \n",
    "quality_mapping = {0: \"God\", 1: \"God\", 2: \"God\", #0-2 er god kvalitet\n",
    "                   3: \"Middels\", 4: \"Middels\", 5: \"Middels\", #3-5 er middels kvalitet\n",
    "                   6: \"Dårlig\", 7: \"Dårlig\"} #6-7 er dårlig kvalitet\n",
    "df['codequality'] = df['codequality'].map(quality_mapping)\n",
    "\n",
    "# Lagrer denne dataen i en ny CSV-fil. Slik at vi kan sammenligne orgnaldataen med den vi har behandlet.\n",
    "data_fil = '../data/BehandletVaerData.csv'\n",
    "df.to_csv(data_fil, index=False)\n",
    "print(f\"Data lagret i {data_fil}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid yellow; padding: 10px; border-radius: 5px;\">\n",
    "<style>\n",
    "p {\n",
    "    line-height: 1.5; \n",
    "}\n",
    "</style>\n",
    "Her har vi gjort om kodekvaliteten fra tilfeldige tall til mer beskrivende tekst. I steden for at kodekvaliteten har et tall mellom 0 og 7, har vi endret det slik at kodekvalitet 0-2 skrives som \"God\", kodekvalitet 3-5 skrives som \"Middels\" og kodekvalitet 6 og 7 skrives som \"Dårlig\". \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antall manglende verdier per kolonne:\n",
      "by                0\n",
      "sourceId          0\n",
      "referenceTime     0\n",
      "statistikk        0\n",
      "variable          0\n",
      "value             0\n",
      "unit              0\n",
      "codequality      10\n",
      "dtype: int64\n",
      "\n",
      "Rader med manglende verdier:\n",
      "Index([287, 320, 1281, 1382, 1415, 1431, 1437, 1440, 1626, 2382], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Henter inn CSV-filen\n",
    "data_fil = '../data/VaerData.csv'  # Tilpass denne stien til hvor CSV-filen faktisk er lagret\n",
    "df = pd.read_csv(data_fil)\n",
    "\n",
    "# Sjekker for manglende verdier i datasettet\n",
    "print(\"Antall manglende verdier per kolonne:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Printer ut radnummeret hvor det mangler verdier\n",
    "print(\"\\nRader med manglende verdier:\")\n",
    "print(df[df.isnull().any(axis=1)].index + 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid yellow; padding: 10px; border-radius: 5px;\">\n",
    "<style>\n",
    "p {\n",
    "    line-height: 1.5; \n",
    "}\n",
    "</style>\n",
    "Her bruker vi Pandas til å identifisere manglende verdier i rådataen. Vi ser at det kun er i kodekvalitet-kolonnen at det er manglende verdier. Det er også listet opp hvilke rader som har manglende verdier. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manglende verdier per kolonne:\n",
      "by                0\n",
      "sourceId          0\n",
      "referenceTime     0\n",
      "statistikk        0\n",
      "variable          0\n",
      "value             0\n",
      "unit              0\n",
      "codequality      10\n",
      "dtype: int64\n",
      "\n",
      "Manglende 'codequality'-verdier fylt med: God\n",
      "\n",
      "Etter utfylling av manglende verdier:\n",
      "by               0\n",
      "sourceId         0\n",
      "referenceTime    0\n",
      "statistikk       0\n",
      "variable         0\n",
      "value            0\n",
      "unit             0\n",
      "codequality      0\n",
      "dtype: int64\n",
      "\n",
      "Oppdatert data lagret i ../data/BehandletVaerData.csv\n",
      "\n",
      "Rader med manglende verdier:\n",
      "Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Henter inn CSV-filen\n",
    "data_fil = '../data/BehandletVaerData.csv' \n",
    "df = pd.read_csv(data_fil)\n",
    "\n",
    "# Sjekker for manglende verdier i datasettet\n",
    "print(\"Manglende verdier per kolonne:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fyller inn manglende 'codequality' med den vanligste verdien\n",
    "most_frequent = df['codequality'].mode()[0]  # Finner vanligste verdi\n",
    "df = df.assign(codequality=df['codequality'].fillna(most_frequent))\n",
    "print(f\"\\nManglende 'codequality'-verdier fylt med: {most_frequent}\")\n",
    "\n",
    "# Printer ut data, nå med utflyltede verdier\n",
    "print(\"\\nEtter utfylling av manglende verdier:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "#Lagrer i BehandletVaerData.csv\n",
    "data_fil = '../data/BehandletVaerData.csv'\n",
    "df.to_csv(data_fil, index=False)\n",
    "print(f\"\\nOppdatert data lagret i {data_fil}\")\n",
    "\n",
    "\n",
    "print(\"\\nRader med manglende verdier:\")\n",
    "print(df[df.isnull().any(axis=1)].index + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid yellow; ding: 10px; border-radius: 5px;\">\n",
    "\n",
    "<style>\n",
    "p {\n",
    "    line-height: 1.5; \n",
    "}\n",
    "</style>\n",
    "Etter vi analyserte og identifiserte hvilke rader som hadde manglende verdier, fylte vi inn verdier der det opprinnelig manglet. Vi fant ut av hvilken kodekvalitet som var den hyppigste, og fylte inn den der det var manglende verdier. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas SQL \n",
    "<div style=\"border: 2px solid yellow; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "<style>\n",
    "p {\n",
    "    line-height: 1.5; \n",
    "}\n",
    "</style>\n",
    "Ved å benytte oss av Pandas SQL får vi muligheten til å kombinere flere operasjoner. Som for eksempel i spørringen under hvor vi har kunnet hente ut gjennomsnittsverdier for de ulike parameterne for de forskjellige byene. Samtidig som vi kun har hentet den dataen med \"God\" kodekvalitet. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          By                 Parameter  gjennomsnittsverdi\n",
      "0  Trondheim       air_temperature P1D            5.539058\n",
      "1  Trondheim  precipitation_amount P1D            2.672877\n",
      "2       Oslo       air_temperature P1D            7.741061\n",
      "3       Oslo  precipitation_amount P1D            1.926301\n",
      "4       Oslo            wind_speed P1D            2.626027\n",
      "5     Bergen       air_temperature P1D            8.924384\n",
      "6     Bergen  precipitation_amount P1D            6.705479\n",
      "7     Bergen            wind_speed P1D            3.571507\n"
     ]
    }
   ],
   "source": [
    "from pandasql import sqldf\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT by as By, variable as Parameter, AVG(value) as gjennomsnittsverdi\n",
    "FROM df\n",
    "WHERE codequality = 'God'\n",
    "GROUP BY By, Parameter\n",
    "ORDER BY By DESC\n",
    "\"\"\"\n",
    "result_df = sqldf(query, locals())\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid yellow; padding: 10px; border-radius: 5px;\">\n",
    "<style>\n",
    "p {\n",
    "    line-height: 1.5; \n",
    "}\n",
    "</style>\n",
    "\n",
    "Å benytte oss av SQL gjør jobben med å hente ut valgri data vesentlig lettere synes vi. Koden som kreves for å lykkes, er mye enklere å forstå, samt på et standardisert format som gjør oppsettet enkelt. Her henter vi for eksempel ut hyppigheten av de ulike kodekvalitetene for hver By. Da får vi det svart på hvit at det meste av dataen vi har hentet er kategorisert som \"God\". Mens det finnes noen få tilfeller for Oslo og Trondheim hvor kodekvaliteten istedenfor er kategorisert som \"Dårlig\" eller \"Middels\".\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          By Kodekvalitet  Antall\n",
      "0  Trondheim       Dårlig       4\n",
      "1  Trondheim          God     726\n",
      "2       Oslo          God    1088\n",
      "3       Oslo      Middels       7\n",
      "4     Bergen          God    1095\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT by as By, codequality as Kodekvalitet, COUNT(*) as Antall\n",
    "FROM df\n",
    "GROUP BY By, Kodekvalitet\n",
    "ORDER BY By DESC\n",
    "\"\"\"\n",
    "result_df = sqldf(query, locals())\n",
    "print(result_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
