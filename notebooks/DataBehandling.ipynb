{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Behandling av værdata\n",
    "\n",
    "I denne filen behandler og manipulerer vi dataen slik at den blir lettere å lese og visualisere – den forberedes for videre analyse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametere: {'sources': 'SN68230,SN18700,SN50540', 'elements': 'mean(air_temperature P1D),sum(precipitation_amount P1D),mean(wind_speed P1D)', 'referencetime': '2022-01-01/2023-01-01', 'timeoffsets': 'default', 'timeresolutions': 'P1D', 'levels': 'default'}\n",
      "Data lagret i ../data/BehandletVaerData.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Henter API-key/Client-id fra .env filen\n",
    "client_id = os.getenv(\"client_id\")\n",
    "\n",
    "with open('../data/Byer.json', 'r') as f:\n",
    "    byer = json.load(f)\n",
    "\n",
    "byerAsString = ','.join(byer.values())\n",
    "\n",
    "element_id = \"mean(air_temperature P1D),sum(precipitation_amount P1D),mean(wind_speed P1D)\"  # Temperatur, nedbør og vindhastighet\n",
    "start_dato = \"2022-01-01\"  # Startdato\n",
    "slutt_dato = \"2023-01-01\"  # Sluttdato\n",
    "\n",
    "# Define endpoint and parameters\n",
    "endpoint = 'https://frost.met.no/observations/v0.jsonld'\n",
    "parameters = {\n",
    "    \"sources\": byerAsString,\n",
    "    \"elements\": element_id,\n",
    "    \"referencetime\": f\"{start_dato}/{slutt_dato}\",\n",
    "    \"timeoffsets\": \"default\",\n",
    "    \"timeresolutions\": \"P1D\",\n",
    "    \"levels\": \"default\"\n",
    "}\n",
    "print(f\"Parametere: {parameters}\")\n",
    "\n",
    "# Sender forespørsel til Frost API\n",
    "response = requests.get(endpoint, params=parameters, auth=(client_id, ''))\n",
    "\n",
    "# Sjekker om forespørselen var vellykket\n",
    "if response.status_code != 200:\n",
    "    print(f\"Error! Status code: {response.status_code}\")\n",
    "    print(f\"Message: {response.json().get('error', {}).get('message', 'Ingen melding gitt')}\")\n",
    "    print(f\"Reason: {response.json().get('error', {}).get('reason', 'Ingen årsak gitt')}\")\n",
    "    exit()\n",
    "\n",
    "# Henter JSON-data\n",
    "json_data = response.json()\n",
    "if 'data' not in json_data:\n",
    "    print(\"Ingen data funnet i forespørselen.\")\n",
    "    print(json_data)\n",
    "    exit()\n",
    "\n",
    "# Prosesserer data til en DataFrame\n",
    "data = json_data['data']\n",
    "rows = []  # Liste for å samle alle rader\n",
    "for item in data:\n",
    "    for observation in item['observations']:\n",
    "        row = {\n",
    "            'sourceId': item['sourceId'].split(':')[0],  # Fjern ':0' fra sourceId\n",
    "            'referenceTime': item['referenceTime'],\n",
    "            'elementId': observation['elementId'],\n",
    "            'value': observation['value'],\n",
    "            'unit': observation['unit'],\n",
    "            'codequality': observation.get('qualityCode', '')  # Henter kvalitetskoden\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "# Opprett DataFrame fra rader\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "# Legger til en ny kolonne for bynavn basert på sourceId\n",
    "df['by'] = df['sourceId'].map({v: k for k, v in byer.items()})\n",
    "\n",
    "# Forenkler tidsformatet (YYYY-MM-DD)\n",
    "df['referenceTime'] = pd.to_datetime(df['referenceTime']).dt.date\n",
    "\n",
    "# Splitter \"elementId\" i flere kolonner\n",
    "df[['statistikk', 'variable']] = df['elementId'].str.extract(r'(\\w+)\\(([^)]+)')\n",
    "\n",
    "# Gjør \"codequality\"-verdiene mer forståelige\n",
    "quality_mapping = {0: \"God\", 1: \"God\", 2: \"God\", \n",
    "                   3: \"Middels\", 4: \"Middels\", 5: \"Middels\",\n",
    "                   6: \"Dårlig\", 7: \"Dårlig\"}\n",
    "df['codequality'] = df['codequality'].map(quality_mapping)\n",
    "\n",
    "# Velger ønskede kolonner\n",
    "df = df[['by', 'sourceId', 'referenceTime', 'statistikk', 'variable', 'value', 'unit', 'codequality']]\n",
    "\n",
    "# Skriver DataFrame til en CSV-fil\n",
    "data_fil = '../data/BehandletVaerData.csv'\n",
    "df.to_csv(data_fil, index=False)\n",
    "print(f\"Data lagret i {data_fil}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her har vi gjort om kodekvaliteten fra tilfeldige tall til mer beskrivende tekst. I steden for at kodekvaliteten har et tall mellom 0 og 7, har vi endret det slik at kodekvalitet 0-2 skrives som \"God\", kodekvalitet 3-5 skrives som \"Middels\" og kodekvalitet 6 og 7 skrives som \"Dårlig\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antall manglende verdier per kolonne:\n",
      "by                0\n",
      "sourceId          0\n",
      "referenceTime     0\n",
      "statistikk        0\n",
      "variable          0\n",
      "value             0\n",
      "unit              0\n",
      "codequality      10\n",
      "dtype: int64\n",
      "\n",
      "Rader med manglende verdier:\n",
      "Index([287, 320, 1281, 1382, 1415, 1431, 1437, 1440, 1626, 2382], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Last inn CSV-filen\n",
    "data_fil = '../data/VaerData.csv'  # Tilpass denne stien til hvor CSV-filen faktisk er lagret\n",
    "df = pd.read_csv(data_fil)\n",
    "\n",
    "# Sjekk for manglende verdier\n",
    "print(\"Antall manglende verdier per kolonne:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Hvis dere vil se hvilke rader som har manglende verdier:\n",
    "print(\"\\nRader med manglende verdier:\")\n",
    "print(df[df.isnull().any(axis=1)].index + 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Her bruker vi Pandas til å identifisere manglende verdier i rådataen. Vi ser at det kun er i kodekvalitet-kolonnen at det er manglende verdier. Det er også listet opp hvilke rader som har manglende verdier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manglende verdier per kolonne:\n",
      "by                0\n",
      "sourceId          0\n",
      "referenceTime     0\n",
      "statistikk        0\n",
      "variable          0\n",
      "value             0\n",
      "unit              0\n",
      "codequality      10\n",
      "dtype: int64\n",
      "\n",
      "Manglende 'codequality'-verdier fylt med: God\n",
      "\n",
      "Etter utfylling av manglende verdier:\n",
      "by               0\n",
      "sourceId         0\n",
      "referenceTime    0\n",
      "statistikk       0\n",
      "variable         0\n",
      "value            0\n",
      "unit             0\n",
      "codequality      0\n",
      "dtype: int64\n",
      "\n",
      "Oppdatert data lagret i ../data/BehandletVaerData.csv\n",
      "\n",
      "Rader med manglende verdier:\n",
      "Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Laster inn CSV-filen\n",
    "data_fil = '../data/BehandletVaerData.csv' \n",
    "df = pd.read_csv(data_fil)\n",
    "\n",
    "# Sjekker for manglende verdier\n",
    "print(\"Manglende verdier per kolonne:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fyller inn manglende 'codequality' med den vanligste verdien\n",
    "most_frequent = df['codequality'].mode()[0]  # Finner vanligste verdi\n",
    "df = df.assign(codequality=df['codequality'].fillna(most_frequent))\n",
    "print(f\"\\nManglende 'codequality'-verdier fylt med: {most_frequent}\")\n",
    "\n",
    "# Sjekker på nytt for å bekrefte at det ikke er flere manglende verdier\n",
    "print(\"\\nEtter utfylling av manglende verdier:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Lagrer den oppdaterte DataFrame-en i CSV-filen\n",
    "data_fil = '../data/BehandletVaerData.csv'\n",
    "df.to_csv(data_fil, index=False)\n",
    "print(f\"\\nOppdatert data lagret i {data_fil}\")\n",
    "\n",
    "# Rader med manglende verdier:\n",
    "print(\"\\nRader med manglende verdier:\")\n",
    "print(df[df.isnull().any(axis=1)].index + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etter vi analyserte og identifiserte hvilke rader som hadde manglende verdier, fylte vi inn verider der det opprinnelig manglet. Vi fant ut av hvilken kodekvalitet som var den hyppigste, og fylte inn den der det var manglende verdier. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
