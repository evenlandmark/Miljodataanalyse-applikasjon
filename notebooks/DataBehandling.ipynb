{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behandling av værdata\n",
    "<div style=\"border: 2px solid yellow; padding: 10px; border-radius: 5px; width: 95%; \">\n",
    "<style>\n",
    "p {\n",
    "    line-height: 1.5; \n",
    "}\n",
    "</style>\n",
    "Her skal vi behandle og manipulere dataen vi har hentet, slik at den blir lettere å lese. Deretter skal vi senere visualisere dette. Vi gjør ulike operasjoner med dataen for å forbedre den for videre analyse, samt forsøker å oppfylle vurderingskriteriene. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Behandlet data lagret i: ../data/BehandletVaerData.csv\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "sys.path.append('../src') \n",
    "from data_behandling import DataBehandler\n",
    "import pandas as pd\n",
    "\n",
    "# Prøver å lese inn rådatafilen. Dersom filen ikke eksisterer eller er ødelagt,\n",
    "# håndteres feilen og det opprettes en tom DataFrame for å unngå at programmet krasjer.\n",
    "try:\n",
    "    df = pd.read_csv('../data/VaerData.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Fant ikke filen 'VaerData.csv'. Har du kjørt HenteData først?\")\n",
    "    df = pd.DataFrame()\n",
    "except pd.errors.ParserError:\n",
    "    print(\"Klarte ikke å lese innholdet i 'VaerData.csv'. Er den kanskje ødelagt?\")\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "# Åpner og leser Byer.json\n",
    "byer = DataBehandler.les_byer_fra_fil('../data/Byer.json')\n",
    "\n",
    "# Oppretter objekt og omstrukturer dataen\n",
    "behandler = DataBehandler(df, byer)\n",
    "\n",
    "df = behandler.omstrukturerer_data()\n",
    "\n",
    "df.head()\n",
    "\n",
    "# Lagrer den behandlede dataen i csv-filen \"BehandletVaerData\" slik at vi kan sammenligne rådataen med den vi har behandlet.\n",
    "behandler.lagre_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid yellow; padding: 10px; border-radius: 5px; width: 95%; \">\n",
    "<style>\n",
    "p {\n",
    "    line-height: 1.5; \n",
    "}\n",
    "</style>\n",
    "I koden over leses rådata-filen først, deretter behandles og omstruktureres den slik at den blir mer oversiktlig og lettere å lese. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manglende verdier før behandling: \n",
      "by                0\n",
      "sourceId          0\n",
      "referenceTime     0\n",
      "statistikk        0\n",
      "variable          0\n",
      "value             0\n",
      "unit              0\n",
      "codequality      10\n",
      "dtype: int64\n",
      "\n",
      "Rader med manglende verdier: \n",
      " Index([287, 320, 1281, 1382, 1415, 1431, 1437, 1440, 1626, 2382], dtype='int64')\n",
      "\n",
      "Manglende verdier etter behandling: \n",
      "by               0\n",
      "sourceId         0\n",
      "referenceTime    0\n",
      "statistikk       0\n",
      "variable         0\n",
      "value            0\n",
      "unit             0\n",
      "codequality      0\n",
      "dtype: int64\n",
      "\n",
      "Behandlet data lagret i: ../data/BehandletVaerData.csv\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from data_behandling import DataBehandler\n",
    "import pandas as pd\n",
    "\n",
    "# Leser inn BehandletVaerData.csv som inneholder behandlet værdata.\n",
    "# Med denne try-except-blokken sikrer vi at notebooken ikke krasjer hvis filen mangler – \n",
    "# altså at vi kan håndtere situasjoner der filen ikke finnes eller er skadet.\n",
    "try:\n",
    "    df = pd.read_csv('../data/BehandletVaerData.csv')\n",
    "except FileNotFoundError:\n",
    "    print(\"Klarte ikke å finne filen 'BehandletVaerData.csv'. Har du kjørt HenteData først?\")\n",
    "    df = pd.DataFrame()\n",
    "except pd.errors.ParserError:\n",
    "    print(\"Klarte ikke å lese CSV-filen. Er den kanskje skadet?\")\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "# Oppretter et objekt av klassen DataBehandler slik at vi kan bruke metodene i klassen\n",
    "behandler = DataBehandler(df, byer)\n",
    "\n",
    "print(f\"Manglende verdier før behandling: \\n{behandler.finn_manglende_verdier()}\")\n",
    "\n",
    "# Printer ut radene hvor det mangler verdier\n",
    "print(f\"\\nRader med manglende verdier: \\n {df[df.isnull().any(axis=1)].index + 2}\")\n",
    "\n",
    "# Behandler manglende verdier\n",
    "df = behandler.fyll_manglende_codequality()\n",
    "\n",
    "print(f\"\\nManglende verdier etter behandling: \\n{behandler.finn_manglende_verdier()}\")\n",
    "\n",
    "#Lagrer i BehandletVaerData.csv\n",
    "behandler.lagre_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid yellow; padding: 10px; border-radius: 5px; width: 95%; \">\n",
    "<style>\n",
    "p {\n",
    "    line-height: 1.5; \n",
    "}\n",
    "</style>\n",
    "Her bruker vi Pandas til å identifisere manglende verdier i rådataen. Vi ser at det kun er i kodekvalitet-kolonnen at det er manglende verdier. Det er også listet opp hvilke rader som har manglende verdier. \n",
    "\n",
    "Etter vi analyserte og identifiserte hvilke rader som hadde manglende verdier, fylte vi inn verdier der det opprinnelig manglet. Vi fant ut av hvilken kodekvalitet som var den hyppigste, og fylte inn den der det var manglende verdier. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Behandlet data lagret i: ../data/BehandletVaerData.csv\n"
     ]
    }
   ],
   "source": [
    "# Klassifiserer \"codequality\"-verdiene\n",
    "df = behandler.klassifiser_codequality()\n",
    "\n",
    "#Lagrer i BehandletVaerData.csv\n",
    "behandler.lagre_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid yellow; padding: 10px; border-radius: 5px; width: 95%; \">\n",
    "<style>\n",
    "p {\n",
    "    line-height: 1.5; \n",
    "}\n",
    "</style>\n",
    "I koden over kaller vi på to metoder som ligger i Python-filen \"data_behandling\", klassifiser_codequality og lagre_data. Disse metodene gjør om kodekvalitetverdiene fra tall og klassifiserer dem i kategoriene \"God\", \"Middels\" og \"Dårlig\", og lagrer den modifiserte og behandlede dataen i csv-filen BehandletVaerData. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas SQL \n",
    "<div style=\"border: 2px solid yellow; padding: 10px; border-radius: 5px; width: 95%; \">\n",
    "<style>\n",
    "p {\n",
    "    line-height: 1.5; \n",
    "}\n",
    "</style>\n",
    "Ved å benytte oss av Pandas SQL får vi muligheten til å kombinere flere operasjoner. Som for eksempel i spørringen under hvor vi har kunnet hente ut gjennomsnittsverdier for de ulike parameterne for de forskjellige byene. Samtidig som vi kun har hentet den dataen med \"God\" kodekvalitet. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          By                 Parameter  Gjennomsnittsverdi\n",
      "0  Trondheim       air_temperature P1D            5.539058\n",
      "1  Trondheim  precipitation_amount P1D            2.672877\n",
      "2       Oslo       air_temperature P1D            7.741061\n",
      "3       Oslo  precipitation_amount P1D            1.926301\n",
      "4       Oslo            wind_speed P1D            2.626027\n",
      "5     Bergen       air_temperature P1D            8.924384\n",
      "6     Bergen  precipitation_amount P1D            6.705479\n",
      "7     Bergen            wind_speed P1D            3.571507\n"
     ]
    }
   ],
   "source": [
    "from pandasql import sqldf\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT by as By, variable as Parameter, AVG(value) as Gjennomsnittsverdi\n",
    "FROM df\n",
    "WHERE codequality = 'God'\n",
    "GROUP BY By, Parameter\n",
    "ORDER BY By DESC\n",
    "\"\"\"\n",
    "result_df = sqldf(query, locals())\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid yellow; padding: 10px; border-radius: 5px; width: 95%; \">\n",
    "<style>\n",
    "p {\n",
    "    line-height: 1.5; \n",
    "}\n",
    "</style>\n",
    "\n",
    "Å benytte oss av SQL gjør jobben med å hente ut valgri data vesentlig lettere synes vi. Koden som kreves for å lykkes, er mye enklere å forstå, samt på et standardisert format som gjør oppsettet enkelt. Her henter vi for eksempel ut hyppigheten av de ulike kodekvalitetene for hver By. Da får vi det svart på hvit at det meste av dataen vi har hentet er kategorisert som \"God\". Mens det finnes noen få tilfeller for Oslo og Trondheim hvor kodekvaliteten istedenfor er kategorisert som \"Dårlig\" eller \"Middels\".\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          By Kodekvalitet  Antall\n",
      "0  Trondheim       Dårlig       4\n",
      "1  Trondheim          God     726\n",
      "2       Oslo          God    1088\n",
      "3       Oslo      Middels       7\n",
      "4     Bergen          God    1095\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT by as By, codequality as Kodekvalitet, COUNT(*) as Antall\n",
    "FROM df\n",
    "GROUP BY By, Kodekvalitet\n",
    "ORDER BY By DESC\n",
    "\"\"\"\n",
    "result_df = sqldf(query, locals())\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fant 140 kalde dager.\n",
      "Antall kalde dager mellom 2022-01-01 og 2023-01-01: 140\n"
     ]
    }
   ],
   "source": [
    "sys.path.append('../src') \n",
    "from tidsintervall import start_dato, slutt_dato\n",
    "\n",
    "# Sjekker hvilke dager som har temperaturer under 0 grader\n",
    "kalde_dager = behandler.tell_kalde_dager()\n",
    "print(f\"Antall kalde dager mellom {start_dato} og {slutt_dato}: {len(kalde_dager)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid yellow; padding: 10px; border-radius: 5px; width: 95%; \">\n",
    "<style>\n",
    "p{\n",
    "    line-height:1.5;\n",
    "}\n",
    "</style>\n",
    "For å ha oversikt over antall dager med minusgrader har vi her kalt på metoden tell_kalde_dager for å finne ut av nettopp det. Det kan være nyttig informasjon å ha til videre analyse av værdataen. I funksjonen tell_kalde_dager har vi brukt list comprehensions for å gjøre koden kortere og lettere å forstå. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid yellow; padding:10px; border-radius: 5px; width: 95%;\">\n",
    "<style>\n",
    "p{\n",
    "    line-height:1.5;\n",
    "}\n",
    "</style>\n",
    "\n",
    "## Uregelmessigheter i dataene og håndtering av dem\n",
    "Vi forventer å møte på uregelmessigheter i dataene våre når vi jobber med dem fremover, og vi har også gjort det allerede. Vi har for eksempel erfart at kodekvaliteten var ganske varierende og uregelmessig, og det håndterte vi ved å endre dataen til et mer forståelig format og fylle inn for de manglende verdiene med den vanligste verdien. Det gjorde vi fordi det statistisk sett er mer sannsynlig at den hyppigste verdien skal være der det er manglende verdier enn noen andre. \n",
    "\n",
    "I tillegg til manglende verdier er det sannsynlig at vi kan møte på f.eks. feilaktige verdier og feilaktige enheter. Den overordnede planen vår for håndtering av uregelmessigheter er at vi må identifisere problemet, deretter rense og formatere dataene og til slutt loggføre uregelmessighetene. Å loggføre uregelmessighetene kan være lurt for å ha en oversikt over hvilke endringer som er gjort med uregelmessig data. \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
