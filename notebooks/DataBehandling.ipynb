{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "p{\n",
    "    line-height:1.5;\n",
    "}\n",
    "</style>\n",
    "## Behandling av værdata\n",
    "<style>\n",
    "p {\n",
    "    line-height: 1.5; \n",
    "}\n",
    "</style>\n",
    "Her skal vi behandle og manipulere dataen vi har hentet, slik at den blir lettere å lese. Deretter skal vi senere visualisere dette. Vi gjør ulike operasjoner med dataen for å forbedre den for videre analyse, samt forsøker å oppfylle vurderingskriteriene. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametere: {'sources': 'SN68230,SN18700,SN50540', 'elements': 'mean(air_temperature P1D),sum(precipitation_amount P1D),mean(wind_speed P1D)', 'referencetime': '2022-01-01/2023-01-01', 'timeoffsets': 'default', 'timeresolutions': 'P1D', 'levels': 'default'}\n",
      "Data lagret i ../data/BehandletVaerData.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Henter API-key/Client-id fra .env filen\n",
    "client_id = os.getenv(\"client_id\")\n",
    "\n",
    "with open('../data/Byer.json', 'r') as f:\n",
    "    byer = json.load(f)\n",
    "\n",
    "byerAsString = ','.join(byer.values())\n",
    "\n",
    "element_id = \"mean(air_temperature P1D),sum(precipitation_amount P1D),mean(wind_speed P1D)\"  # Temperatur, nedbør og vindhastighet\n",
    "start_dato = \"2022-01-01\"\n",
    "slutt_dato = \"2023-01-01\" \n",
    "\n",
    "# Definerer paramtere\n",
    "endpoint = 'https://frost.met.no/observations/v0.jsonld'\n",
    "parameters = {\n",
    "    \"sources\": byerAsString,\n",
    "    \"elements\": element_id,\n",
    "    \"referencetime\": f\"{start_dato}/{slutt_dato}\",\n",
    "    \"timeoffsets\": \"default\",\n",
    "    \"timeresolutions\": \"P1D\",\n",
    "    \"levels\": \"default\"\n",
    "}\n",
    "print(f\"Parametere: {parameters}\")\n",
    "\n",
    "# Sender forespørsel til Frost API\n",
    "response = requests.get(endpoint, params=parameters, auth=(client_id, ''))\n",
    "\n",
    "# Sjekker om forespørselen var vellykket\n",
    "if response.status_code != 200:\n",
    "    print(f\"Error! Status code: {response.status_code}\")\n",
    "    print(f\"Message: {response.json().get('error', {}).get('message', 'Ingen melding gitt')}\")\n",
    "    print(f\"Reason: {response.json().get('error', {}).get('reason', 'Ingen årsak gitt')}\")\n",
    "    exit()\n",
    "\n",
    "# Henter JSON-data\n",
    "json_data = response.json()\n",
    "if 'data' not in json_data:\n",
    "    print(\"Ingen data funnet i forespørselen.\")\n",
    "    print(json_data)\n",
    "    exit()\n",
    "\n",
    "# Prosesserer data til en DataFrame\n",
    "data = json_data['data']\n",
    "rows = []\n",
    "for item in data:\n",
    "    for observation in item['observations']:\n",
    "        row = {\n",
    "            'sourceId': item['sourceId'].split(':')[0],\n",
    "            'referenceTime': item['referenceTime'],\n",
    "            'elementId': observation['elementId'],\n",
    "            'value': observation['value'],\n",
    "            'unit': observation['unit'],\n",
    "            'codequality': observation.get('qualityCode', '')  # Henter kvalitetskoden\n",
    "        }\n",
    "        rows.append(row)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "\n",
    "# Gjør om litt på dataer slik at de blir lettere å jobbe med og penere å se på i CSV-filen.\n",
    "df['referenceTime'] = pd.to_datetime(df['referenceTime']).dt.date # Fjerner tid og beholder bare dato\n",
    "df[['statistikk', 'variable']] = df['elementId'].str.extract(r'(\\w+)\\(([^)]+)') # Splitter elementId i to kolonner, en for verdi og en for enhet. \n",
    "df['by'] = df['sourceId'].map({v: k for k, v in byer.items()})  # Legger til en ny kolonne for bynavn basert på sourceId\n",
    "df = df[['by', 'sourceId', 'referenceTime', 'statistikk', 'variable', 'value', 'unit', 'codequality']] #Endrer på oppsettet på kolonnene i dataen vi henter ut.\n",
    "\n",
    "# Gjør \"codequality\"-verdiene mer forståelige ved bruk av list comprehensions\n",
    "df['codequality'] = [\"God\" if x in [0, 1, 2] else \"Middels\" if x in [3, 4, 5] else \"Dårlig\" for x in df['codequality']]\n",
    "\n",
    "# Lagrer denne dataen i en ny CSV-fil. Slik at vi kan sammenligne orgnaldataen med den vi har behandlet.\n",
    "data_fil = '../data/BehandletVaerData.csv'\n",
    "df.to_csv(data_fil, index=False)\n",
    "print(f\"Data lagret i {data_fil}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid yellow; padding: 10px; border-radius: 5px;\">\n",
    "<style>\n",
    "p {\n",
    "    line-height: 1.5; \n",
    "}\n",
    "</style>\n",
    "Her har vi gjort om kodekvaliteten fra tilfeldige tall til mer beskrivende tekst. I steden for at kodekvaliteten har et tall mellom 0 og 7, har vi endret det slik at kodekvalitet 0-2 skrives som \"God\", kodekvalitet 3-5 skrives som \"Middels\" og kodekvalitet 6 og 7 skrives som \"Dårlig\". \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antall manglende verdier per kolonne:\n",
      "by                0\n",
      "sourceId          0\n",
      "referenceTime     0\n",
      "statistikk        0\n",
      "variable          0\n",
      "value             0\n",
      "unit              0\n",
      "codequality      10\n",
      "dtype: int64\n",
      "\n",
      "Rader med manglende verdier:\n",
      "Index([287, 320, 1281, 1382, 1415, 1431, 1437, 1440, 1626, 2382], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Henter inn CSV-filen\n",
    "data_fil = '../data/VaerData.csv'  # Tilpass denne stien til hvor CSV-filen faktisk er lagret\n",
    "df = pd.read_csv(data_fil)\n",
    "\n",
    "# Sjekker for manglende verdier i datasettet\n",
    "print(\"Antall manglende verdier per kolonne:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Printer ut radnummeret hvor det mangler verdier\n",
    "print(\"\\nRader med manglende verdier:\")\n",
    "print(df[df.isnull().any(axis=1)].index + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid yellow; padding: 10px; border-radius: 5px;\">\n",
    "<style>\n",
    "p {\n",
    "    line-height: 1.5; \n",
    "}\n",
    "</style>\n",
    "Her bruker vi Pandas til å identifisere manglende verdier i rådataen. Vi ser at det kun er i kodekvalitet-kolonnen at det er manglende verdier. Det er også listet opp hvilke rader som har manglende verdier. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manglende verdier per kolonne:\n",
      "by               0\n",
      "sourceId         0\n",
      "referenceTime    0\n",
      "statistikk       0\n",
      "variable         0\n",
      "value            0\n",
      "unit             0\n",
      "codequality      0\n",
      "dtype: int64\n",
      "\n",
      "Manglende 'codequality'-verdier fylt med: God\n",
      "\n",
      "Etter utfylling av manglende verdier:\n",
      "by               0\n",
      "sourceId         0\n",
      "referenceTime    0\n",
      "statistikk       0\n",
      "variable         0\n",
      "value            0\n",
      "unit             0\n",
      "codequality      0\n",
      "dtype: int64\n",
      "\n",
      "Oppdatert data lagret i ../data/BehandletVaerData.csv\n",
      "\n",
      "Rader med manglende verdier:\n",
      "Index([], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Henter inn CSV-filen\n",
    "data_fil = '../data/BehandletVaerData.csv' \n",
    "df = pd.read_csv(data_fil)\n",
    "\n",
    "# Sjekker for manglende verdier i datasettet\n",
    "print(\"Manglende verdier per kolonne:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fyller inn manglende 'codequality' med den vanligste verdien\n",
    "vanligste_verdi = df['codequality'].mode()[0]  # Finner vanligste verdi\n",
    "df = df.assign(codequality=df['codequality'].fillna(vanligste_verdi))\n",
    "print(f\"\\nManglende 'codequality'-verdier fylt med: {vanligste_verdi}\")\n",
    "\n",
    "# Printer ut data, nå med utflyltede verdier\n",
    "print(\"\\nEtter utfylling av manglende verdier:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "#Lagrer i BehandletVaerData.csv\n",
    "data_fil = '../data/BehandletVaerData.csv'\n",
    "df.to_csv(data_fil, index=False)\n",
    "print(f\"\\nOppdatert data lagret i {data_fil}\")\n",
    "\n",
    "\n",
    "print(\"\\nRader med manglende verdier:\")\n",
    "print(df[df.isnull().any(axis=1)].index + 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid yellow; ding: 10px; border-radius: 5px;\">\n",
    "\n",
    "<style>\n",
    "p {\n",
    "    line-height: 1.5; \n",
    "}\n",
    "</style>\n",
    "Etter vi analyserte og identifiserte hvilke rader som hadde manglende verdier, fylte vi inn verdier der det opprinnelig manglet. Vi fant ut av hvilken kodekvalitet som var den hyppigste, og fylte inn den der det var manglende verdier. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas SQL \n",
    "<div style=\"border: 2px solid yellow; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "<style>\n",
    "p {\n",
    "    line-height: 1.5; \n",
    "}\n",
    "</style>\n",
    "Ved å benytte oss av Pandas SQL får vi muligheten til å kombinere flere operasjoner. Som for eksempel i spørringen under hvor vi har kunnet hente ut gjennomsnittsverdier for de ulike parameterne for de forskjellige byene. Samtidig som vi kun har hentet den dataen med \"God\" kodekvalitet. \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          By                 Parameter  gjennomsnittsverdi\n",
      "0  Trondheim       air_temperature P1D            5.539058\n",
      "1  Trondheim  precipitation_amount P1D            2.672877\n",
      "2       Oslo       air_temperature P1D            7.741061\n",
      "3       Oslo  precipitation_amount P1D            1.926301\n",
      "4       Oslo            wind_speed P1D            2.626027\n",
      "5     Bergen       air_temperature P1D            8.924384\n",
      "6     Bergen  precipitation_amount P1D            6.705479\n",
      "7     Bergen            wind_speed P1D            3.571507\n"
     ]
    }
   ],
   "source": [
    "from pandasql import sqldf\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT by as By, variable as Parameter, AVG(value) as gjennomsnittsverdi\n",
    "FROM df\n",
    "WHERE codequality = 'God'\n",
    "GROUP BY By, Parameter\n",
    "ORDER BY By DESC\n",
    "\"\"\"\n",
    "result_df = sqldf(query, locals())\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid yellow; padding: 10px; border-radius: 5px;\">\n",
    "<style>\n",
    "p {\n",
    "    line-height: 1.5; \n",
    "}\n",
    "</style>\n",
    "\n",
    "Å benytte oss av SQL gjør jobben med å hente ut valgri data vesentlig lettere synes vi. Koden som kreves for å lykkes, er mye enklere å forstå, samt på et standardisert format som gjør oppsettet enkelt. Her henter vi for eksempel ut hyppigheten av de ulike kodekvalitetene for hver By. Da får vi det svart på hvit at det meste av dataen vi har hentet er kategorisert som \"God\". Mens det finnes noen få tilfeller for Oslo og Trondheim hvor kodekvaliteten istedenfor er kategorisert som \"Dårlig\" eller \"Middels\".\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          By Kodekvalitet  Antall\n",
      "0  Trondheim       Dårlig       4\n",
      "1  Trondheim          God     726\n",
      "2       Oslo          God    1088\n",
      "3       Oslo      Middels       7\n",
      "4     Bergen          God    1095\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT by as By, codequality as Kodekvalitet, COUNT(*) as Antall\n",
    "FROM df\n",
    "GROUP BY By, Kodekvalitet\n",
    "ORDER BY By DESC\n",
    "\"\"\"\n",
    "result_df = sqldf(query, locals())\n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Antall dager mellom 2022-01-01 og 2023-01-01 med temperatur under 0 grader: 140\n"
     ]
    }
   ],
   "source": [
    "# Sjekker hvilke dager som har temperaturer under 0 grader\n",
    "dager_negativ_temp = [row for index, row in df.iterrows() if row['value'] < 0 and row['variable'] == \"air_temperature P1D\"]\n",
    "\n",
    "print(f\"Antall dager mellom {start_dato} og {slutt_dato} med temperatur under 0 grader: {len(dager_negativ_temp)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:2px solid yellow; padding:10px;border-radius:5px;\">\n",
    "<style>\n",
    "p{\n",
    "    line-height:1.5;\n",
    "}\n",
    "</style>\n",
    "For å ha oversikt over antall dager med minusgrader vi har, brukte vi her list comprehensions til å finne ut av nettopp det. Det kan være nyttig informasjon å ha til videre analyse av værdataen. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:2px solid yellow; padding:10px;border-radius:5px;\">\n",
    "<style>\n",
    "p{\n",
    "    line-height:1.5;\n",
    "}\n",
    "</style>\n",
    "\n",
    "## Uregelmessigheter i dataene og håndtering av dem\n",
    "Vi forventer å møte på uregelmessigheter i dataene våre når vi jobber med dem fremover, og vi har også gjort det allerede. Vi har for eksempel erfart at kodekvaliteten var ganske varierende og uregelmessig, og det håndterte vi ved å endre dataen til et mer forståelig format og fylle inn for de manglende verdiene med den vanligste verdien. Det gjorde vi fordi det statistisk sett er mer sannsynlig at den hyppigste verdien skal være der det er manglende verdier enn noen andre. \n",
    "\n",
    "I tillegg til manglende verdier er det sannsynlig at vi kan møte på f.eks. feilaktige verdier og feilaktige enheter. Den overordnede planen vår for håndtering av uregelmessigheter er at vi må identifisere problemet, deretter rense og formatere dataene og til slutt loggføre uregelmessighetene. Å loggføre uregelmessighetene kan være lurt for å ha en oversikt over hvilke endringer som er gjort med uregelmessig data. \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
